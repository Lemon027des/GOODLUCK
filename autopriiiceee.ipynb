{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a17671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:09:44.913835Z",
     "iopub.status.busy": "2025-11-18T22:09:44.913562Z",
     "iopub.status.idle": "2025-11-18T22:10:10.493130Z",
     "shell.execute_reply": "2025-11-18T22:10:10.492554Z",
     "shell.execute_reply.started": "2025-11-18T22:09:44.913814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoImageProcessor, AutoModel\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/__init__.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     30\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     is_pretty_midi_available,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     ClassAttrs,\n\u001b[1;32m     24\u001b[0m     ClassDocstring,\n\u001b[1;32m     25\u001b[0m     ImageProcessorArgs,\n\u001b[1;32m     26\u001b[0m     ModelArgs,\n\u001b[1;32m     27\u001b[0m     ModelOutputArgs,\n\u001b[1;32m     28\u001b[0m     auto_class_docstring,\n\u001b[1;32m     29\u001b[0m     auto_docstring,\n\u001b[1;32m     30\u001b[0m     get_args_doc_from_source,\n\u001b[1;32m     31\u001b[0m     parse_docstring,\n\u001b[1;32m     32\u001b[0m     set_min_indent,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/auto_docstring.py:30\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mregex\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODELS_TO_PIPELINE,\n\u001b[1;32m     26\u001b[0m     PIPELINE_TASKS_TO_SAMPLE_DOCSTRINGS,\n\u001b[1;32m     27\u001b[0m     PT_SAMPLE_DOCSTRINGS,\n\u001b[1;32m     28\u001b[0m     _prepare_output_docstrings,\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelOutput\n\u001b[1;32m     33\u001b[0m PATH_TO_TRANSFORMERS \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m AUTODOC_FILES \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_*.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodeling_*.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_extractor_*.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/generic.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m _is_torch_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# required for @can_return_tuple decorator to work with torchdynamo\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_debugging_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_addition_debugger_context\n\u001b[1;32m     49\u001b[0m     _is_torch_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/__init__.py:409\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    408\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSymInt\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:463\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2488c4cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:32.987243Z",
     "iopub.status.busy": "2025-11-18T22:10:32.986573Z",
     "iopub.status.idle": "2025-11-18T22:10:33.074833Z",
     "shell.execute_reply": "2025-11-18T22:10:33.073914Z",
     "shell.execute_reply.started": "2025-11-18T22:10:32.987218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/vseros-avito-stage1/train_dataset.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/293576859.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/vseros-avito-stage1/train_dataset.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/vseros-avito-stage1/test_dataset.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_TARGET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/vseros-avito-stage1/train_dataset.parquet'"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"/kaggle/input/vseros-avito-stage1/train_dataset.parquet\")\n",
    "test = pd.read_parquet(\"/kaggle/input/vseros-avito-stage1/test_dataset.parquet\")\n",
    "train['target'] = np.log(train['price_TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6468142-bda9-4c97-ab06-db4f7d4c18d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T21:37:20.684411Z",
     "iopub.status.busy": "2025-11-18T21:37:20.683825Z",
     "iopub.status.idle": "2025-11-18T21:37:20.692097Z",
     "shell.execute_reply": "2025-11-18T21:37:20.691434Z",
     "shell.execute_reply.started": "2025-11-18T21:37:20.684383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        10.839581\n",
       "1        12.180755\n",
       "2        15.796650\n",
       "3        13.880362\n",
       "4        10.896739\n",
       "           ...    \n",
       "69995    13.691080\n",
       "69996    13.208541\n",
       "69997    12.581079\n",
       "69998    12.587928\n",
       "69999    13.921671\n",
       "Name: target, Length: 70000, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "078f7ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T21:37:22.347679Z",
     "iopub.status.busy": "2025-11-18T21:37:22.347425Z",
     "iopub.status.idle": "2025-11-18T21:37:22.376963Z",
     "shell.execute_reply": "2025-11-18T21:37:22.376382Z",
     "shell.execute_reply.started": "2025-11-18T21:37:22.347662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98075"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"/kaggle/input/vseros-avito-stage1/AvitoAuto/АвтоПрайс/test_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aed6994-afd3-49f2-84ca-bd48ca39bd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T21:37:22.831521Z",
     "iopub.status.busy": "2025-11-18T21:37:22.831219Z",
     "iopub.status.idle": "2025-11-18T21:37:25.047911Z",
     "shell.execute_reply": "2025-11-18T21:37:25.047295Z",
     "shell.execute_reply.started": "2025-11-18T21:37:22.831499Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273873"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"/kaggle/input/vseros-avito-stage1/AvitoAuto/АвтоПрайс/train_images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257769ea-e01e-4042-a943-b8eed4d6f373",
   "metadata": {},
   "source": [
    "# EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a633609a-76b3-4869-b22d-f6255dafb858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T21:58:33.373593Z",
     "iopub.status.busy": "2025-11-18T21:58:33.373265Z",
     "iopub.status.idle": "2025-11-18T21:58:33.978925Z",
     "shell.execute_reply": "2025-11-18T21:58:33.978259Z",
     "shell.execute_reply.started": "2025-11-18T21:58:33.373570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTModel(\n",
       "  (embeddings): ViTEmbeddings(\n",
       "    (patch_embeddings): ViTPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ViTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ViTLayer(\n",
       "        (attention): ViTAttention(\n",
       "          (attention): ViTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): ViTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (pooler): Identity()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\", use_fast=True)\n",
    "vit_model = AutoModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "del vit_model.pooler\n",
    "vit_model.pooler = torch.nn.Identity()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_model.to(device)\n",
    "vit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dc39a20-40a7-4008-99ca-325d632dfb2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T21:58:37.114694Z",
     "iopub.status.busy": "2025-11-18T21:58:37.114137Z",
     "iopub.status.idle": "2025-11-18T21:58:39.559353Z",
     "shell.execute_reply": "2025-11-18T21:58:39.558610Z",
     "shell.execute_reply.started": "2025-11-18T21:58:37.114673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images dir exists: True\n",
      "Test images dir exists: True\n",
      "Found 273873 train images, 98075 test images\n"
     ]
    }
   ],
   "source": [
    "train_image_dir = '/kaggle/input/vseros-avito-stage1/AvitoAuto/АвтоПрайс/train_images'\n",
    "test_image_dir = '/kaggle/input/vseros-avito-stage1/AvitoAuto/АвтоПрайс/test_images'\n",
    "\n",
    "print(f\"Train images dir exists: {os.path.exists(train_image_dir)}\")\n",
    "print(f\"Test images dir exists: {os.path.exists(test_image_dir)}\")\n",
    "\n",
    "# Проверим какие файлы есть в директориях\n",
    "train_files = glob.glob(os.path.join(train_image_dir, \"*.jpg\"))\n",
    "test_files = glob.glob(os.path.join(test_image_dir, \"*.jpg\"))\n",
    "print(f\"Found {len(train_files)} train images, {len(test_files)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0aa5bd5b-3b8a-4b2a-8aa1-ef77ee7996df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T21:58:41.574228Z",
     "iopub.status.busy": "2025-11-18T21:58:41.573550Z",
     "iopub.status.idle": "2025-11-18T21:58:41.581647Z",
     "shell.execute_reply": "2025-11-18T21:58:41.580764Z",
     "shell.execute_reply.started": "2025-11-18T21:58:41.574205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CarImageDataset(Dataset):\n",
    "    def __init__(self, folder, train=True):\n",
    "        self.folder = folder\n",
    "        self.image_paths = []\n",
    "        self.ID2Images = {}\n",
    "        self.train = train\n",
    "\n",
    "        for img in sorted(os.listdir(folder)):\n",
    "            path = os.path.join(folder, img)\n",
    "            ID = img.split(\"_\")[0]\n",
    "            self.image_paths.append(path)\n",
    "            self.ID2Images.setdefault(int(ID), [])\n",
    "            self.ID2Images[int(ID)].append(path)\n",
    "\n",
    "        self.ids = sorted(self.ID2Images.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ID = self.ids[idx]\n",
    "        image_paths = self.ID2Images[ID]\n",
    "        \n",
    "        images = [Image.open(img).convert(\"RGB\") for img in image_paths]\n",
    "        processed = processor(images, return_tensors=\"pt\")\n",
    "        processed = {k: v.to(device) for k, v in processed.items()}\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = vit_model(**processed)\n",
    "            cls_embed = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        if self.train:\n",
    "            log_target = train.loc[train[train.ID == ID].index[0], \"target\"]\n",
    "            target = train.loc[train[train.ID == ID].index[0], \"price_TARGET\"]\n",
    "            return ID, torch.mean(cls_embed, dim=0).detach().cpu().numpy()\n",
    "        else:\n",
    "            return ID, torch.mean(cls_embed, dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "728c3b89-f96e-45fa-9b76-60a0933b851e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T21:58:49.073392Z",
     "iopub.status.busy": "2025-11-18T21:58:49.073097Z",
     "iopub.status.idle": "2025-11-18T21:58:51.716878Z",
     "shell.execute_reply": "2025-11-18T21:58:51.716305Z",
     "shell.execute_reply.started": "2025-11-18T21:58:49.073371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = CarImageDataset(train_image_dir, train=True)\n",
    "data_test = CarImageDataset(test_image_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0766b58-077e-4c43-ab10-0891f4d377e2",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4078d8-2dae-41b0-82f3-0521f4fdc2dd",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2)).item()\n",
    "\n",
    "def mape(y_true, y_pred, eps=1e-8):\n",
    "    return (torch.mean(torch.abs((y_true - y_pred) / (y_true + eps))) * 100).item()\n",
    "\n",
    "def median_ape(y_true, y_pred, eps=1e-8):\n",
    "    return torch.median(torch.abs((y_true - y_pred) / (y_true + eps)) * 100).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb84ba2-08c6-48d6-97b2-e7587d930253",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77948e15-169e-463e-8fe4-a73ecf6cee00",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# train/val split\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "num_epochs = 3\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_steps = num_epochs * steps_per_epoch\n",
    "\n",
    "# модель\n",
    "model = EmbedAggregator(embed_dim=768, hidden_dim=512)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-7)\n",
    "loss_fn = nn.MSELoss()  # оптимизируем RMSE в лог-пространстве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46039118-7395-4938-9bdd-9f2b35217c51",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"ЧЕКПОИНТ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d7986-55f8-463b-8151-a48474e32008",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "vit_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620edb0-d143-440d-99d7-85f8933133b7",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# best_median_ape = float(\"inf\")\n",
    "# best_model_path = \"best_model.pt\"\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     # ---- TRAIN ----\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "#     for IDs, embeds, log_targets, targets in pbar:\n",
    "#         embeds = embeds.to(device)\n",
    "#         log_targets = log_targets.to(device)\n",
    "\n",
    "#         preds = model(embeds)  # предсказание в log-пространстве\n",
    "#         loss = loss_fn(preds, log_targets)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_loss += loss.item()\n",
    "#         pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "#     scheduler.step()\n",
    "\n",
    "#     # ---- VALID ----\n",
    "#     model.eval()\n",
    "#     val_preds, val_targets = [], []\n",
    "#     val_loss = 0\n",
    "#     pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Valid]\", leave=False)\n",
    "#     with torch.no_grad():\n",
    "#         for IDs, embeds, log_targets, targets in pbar:\n",
    "#             embeds = embeds.to(device)\n",
    "#             log_targets = log_targets.to(device)\n",
    "\n",
    "#             preds = model(embeds)\n",
    "#             loss = loss_fn(preds, log_targets)\n",
    "#             val_loss += loss.item()\n",
    "\n",
    "#             # переводим обратно из log → exp\n",
    "#             preds_real = torch.exp(preds.cpu())\n",
    "#             targets_real = targets\n",
    "\n",
    "#             val_preds.append(preds_real)\n",
    "#             val_targets.append(targets_real)\n",
    "\n",
    "#             pbar.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "#     val_preds = torch.cat(val_preds)\n",
    "#     val_targets = torch.cat(val_targets)\n",
    "\n",
    "#     # метрики\n",
    "#     val_rmse = rmse(val_targets, val_preds)\n",
    "#     val_mape = mape(val_targets, val_preds)\n",
    "#     val_median_ape = median_ape(val_targets, val_preds)\n",
    "\n",
    "#     print(f\"\\nEpoch {epoch+1}\")\n",
    "#     print(f\"  Train loss (log-space): {train_loss/len(train_loader):.4f}\")\n",
    "#     print(f\"  Val loss (log-space): {val_loss/len(val_loader):.4f}\")\n",
    "#     print(f\"  Val RMSE: {val_rmse:.2f}\")\n",
    "#     print(f\"  Val MAPE: {val_mape:.2f}%\")\n",
    "#     print(f\"  Val MedianAPE: {val_median_ape:.2f}%\")\n",
    "\n",
    "#     # ---- SAVE BEST MODEL ----\n",
    "#     if val_median_ape < best_median_ape:\n",
    "#         best_median_ape = val_median_ape\n",
    "#         torch.save(model.state_dict(), best_model_path)\n",
    "#         print(f\"  ✅ New best model saved! MedianAPE = {best_median_ape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46684734-d483-4058-a9fb-e977158ea150",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/kaggle/working/best_model.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99e2cc-fea6-4a13-9ceb-7860bb6c4e48",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CarImageDataset(train_image_dir, train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=80, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = CarImageDataset(test_image_dir, train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=80, shuffle=False, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fc27e-f6c1-4cb6-b4b0-4806f75c6c3b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_all_embeds(dataloader, vit_model, device):\n",
    "    vit_model.eval()\n",
    "    all_ids = []\n",
    "    all_embeds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for IDs, embeds, *rest in tqdm(dataloader):\n",
    "            \n",
    "            batch_embeds = []\n",
    "            \n",
    "            for embed in embeds: # embed: [num_images, 768]\n",
    "                embed = embed.to(device)\n",
    "                # если нужно прогнать через Vit (CLS эмбеддинг уже есть в embeds)\n",
    "                batch_embeds.append(embed.cpu())  # [num_images, 768]\n",
    "\n",
    "            \n",
    "            # конкатим все эмбеддинги по ID\n",
    "            batch_embeds = [e.flatten() for e in batch_embeds]  # [num_images*768]\n",
    "            all_embeds.extend(batch_embeds)\n",
    "            all_ids.extend(IDs)\n",
    "\n",
    "    all_embeds = torch.stack(all_embeds, dim=1)  # [embed_dim_flat, train_size]\n",
    "    return all_ids, all_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9f65b-47a5-4475-8af6-5d89809090fe",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_final_embeds(dataloader, model, device):\n",
    "    \"\"\"\n",
    "    Извлекает финальные эмбеддинги из модели EmbedAggregator для каждого ID.\n",
    "    Возвращает:\n",
    "        - all_ids: список ID\n",
    "        - all_embeds: torch.Tensor [num_IDs, hidden_dim]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_ids = []\n",
    "    all_embeds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Extracting final embeddings\"):\n",
    "            IDs, embeds, *rest = batch  # rest игнорируем\n",
    "            embeds = embeds.to(device)  # [batch_size, num_images, embed_dim]\n",
    "\n",
    "            agg_embeds = model(embeds)  # [batch_size, hidden_dim]\n",
    "            agg_embeds = agg_embeds.cpu()\n",
    "\n",
    "            all_ids.extend(IDs)\n",
    "            all_embeds.append(agg_embeds)\n",
    "\n",
    "    all_embeds = torch.cat(all_embeds, dim=0)  # [num_IDs, hidden_dim]\n",
    "    return all_ids, all_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d141657-d123-49f1-94cf-6d88cea69ee5",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ids, train_agg_embeds = extract_all_embeds(train_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa65f9-4224-4093-bf19-73762735a202",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_ids, test_agg_embeds = extract_all_embeds(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9f7cf-a04f-4f02-903b-6da39eafb3c8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_agg_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac4dcaa-5684-4630-80ee-70bd73fd8b85",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_agg_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085dc558-916e-493b-84da-351011d0db1d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "train_embeds_cut = train_agg_embeds[:768, :]  # берём первые 768 эмбеддингов\n",
    "train_emb_df = pd.DataFrame(train_embeds_cut.T, columns=[f\"emb_{i}\" for i in range(768)])\n",
    "emb_cols = train_emb_df.columns\n",
    "train_emb_df[\"ID\"] = train_ids\n",
    "train_df = train.merge(train_emb_df, on=\"ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d93f73-8ec8-4f06-a3c1-a599747e9102",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_embeds_cut = test_agg_embeds[:768, :]\n",
    "test_emb_df = pd.DataFrame(test_embeds_cut.T, columns=[f\"emb_{i}\" for i in range(768)])\n",
    "test_emb_df[\"ID\"] = test_ids\n",
    "test_df = test.merge(test_emb_df, on=\"ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d751e-32eb-4839-811f-5552f47ae4ef",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32db3c5-08f6-43e0-994a-a4e53b8f3a62",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b511273-7b15-4660-9bab-a11740e4f0a3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad16986-4f71-4af3-af57-ac69ba9bcd68",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f82de-af3f-401a-af0d-1f4590db3e06",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c9eef-bc34-4c6c-8e13-886181a0a7cb",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262922d-edc1-4000-8638-978ebc97e0e3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab696d-3926-4c18-ae21-765a036c5f40",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db82a3-50e8-46ee-9367-db4edc5cea3a",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1466352-a318-4f5d-a35b-3ccd091d2760",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed919d0-b798-44a5-8a25-58d354115261",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30939bf5-4e18-411c-af0f-2a624a6deb9d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad354232-fadf-45fd-94b1-45aa0d8ac8c8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5beaee-d6dc-4a6e-a776-1ded8321d6eb",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ef44e-6afe-43bf-a5b1-a15525bd324e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d1bb3-e8ed-4d5a-b017-07a3772dbe72",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e0e0f-e958-4cf2-8745-ba0b9365d57d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24ee31ae-2de3-48c7-9766-b06973c3c691",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021c29c",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['equipment', 'body_type', 'drive_type', 'engine_type', 'doors_number', 'color', 'pts', 'diski', 'audiosistema', 'electropodemniki', 'fary', 'salon', 'upravlenie_klimatom',\n",
    "                'usilitel_rul', 'steering_wheel', 'crashes_count', 'owners_count']\n",
    "numeric_features = ['mileage', 'latitude', 'longitude'] + np.array(emb_cols).tolist()\n",
    "\n",
    "listed_features = ['aktivnaya_bezopasnost_mult', 'audiosistema_mult', 'shini_i_diski_mult', 'electroprivod_mult', 'fary_mult', 'multimedia_navigacia_mult', 'obogrev_mult', 'pamyat_nastroek_mult', 'podushki_bezopasnosti_mult',\n",
    "                   'pomosh_pri_vozhdenii_mult', 'protivoygonnaya_sistema_mult', 'salon_mult', 'upravlenie_klimatom_mult']\n",
    "\n",
    "target = ['price_TARGET']\n",
    "ID = ['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bda8a",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e4e75",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Собираем все уникальные метки для train и test\n",
    "labels = {col: set().union(*train[col]) for col in listed_features}\n",
    "test_labels = {col: set().union(*test[col]) for col in listed_features}\n",
    "\n",
    "# One-hot для train\n",
    "for col in listed_features:\n",
    "    # Разворачиваем список в строки\n",
    "    exploded = train[[col]].explode(col)\n",
    "    # Получаем one-hot кодировку\n",
    "    dummies = pd.get_dummies(exploded[col], prefix=col)\n",
    "    # Складываем обратно по индексам\n",
    "    dummies = dummies.groupby(exploded.index).max()\n",
    "    # Добавляем в train\n",
    "    train = train.join(dummies)\n",
    "\n",
    "# One-hot для test\n",
    "for col in listed_features:\n",
    "    exploded = test[[col]].explode(col)\n",
    "    dummies = pd.get_dummies(exploded[col], prefix=col)\n",
    "    dummies = dummies.groupby(exploded.index).max()\n",
    "    test = test.join(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c88071",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i, lbs in enumerate(labels):\n",
    "    print(lbs, labels[lbs] == test_labels[lbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c30f1",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    if col not in target and col not in listed_features and col not in numeric_features and col not in cat_features and col not in ID:\n",
    "        cat_features.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09698947",
   "metadata": {},
   "source": [
    "## CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b952b9-6733-4532-90e4-cfae6c7fdd8e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc69e6",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892bcd4-b97f-4207-8c3c-053531add226",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U \"scikit-learn<1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22aed6-c41c-4e7a-95ff-52b972745057",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9f593",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "test[cat_features] = test[cat_features].fillna(\"NaN\")\n",
    "train[cat_features] = train[cat_features].fillna(\"NaN\")\n",
    "\n",
    "train['target'] = np.log(train['price_TARGET'])\n",
    "\n",
    "class MedianAPE:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_median_ape(y_true, y_pred, eps=1e-8):\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n",
    "    \n",
    "    def is_max_optimal(self):\n",
    "        return False  # чем меньше MdAPE, тем лучше\n",
    "    \n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        y_true = np.array(target)\n",
    "        y_pred = np.array(approxes[0])\n",
    "        score = self.get_median_ape(y_true, y_pred)\n",
    "        return score, 1  # (значение метрики, вес)\n",
    "    \n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "\n",
    "X = train[cat_features + numeric_features]\n",
    "y = train['target']\n",
    "\n",
    "indices = np.arange(len(train))\n",
    "np.random.seed(52)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(0.9 * len(indices))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=52, shuffle=True)\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "    iterations=7500,\n",
    "    learning_rate=0.03,\n",
    "    depth=10,\n",
    "    cat_features=cat_features,\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    verbose=100,\n",
    "    random_seed=42,\n",
    "    task_type=\"GPU\"\n",
    ")\n",
    "\n",
    "model.fit(X=X_train, y=y_train, eval_set=(X_val, y_val),\n",
    "          cat_features=cat_features, use_best_model=True)\n",
    "\n",
    "\n",
    "def median_APE(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n",
    "\n",
    "y_pred = np.exp(model.predict(X_val))\n",
    "y_val = train.loc[X_val.index, \"price_TARGET\"]\n",
    "score = median_APE(y_val, y_pred)\n",
    "print(f\"Median_APE: {score}\\n\" +\n",
    "      f\"LB: {1 / (1 + score)}\\n\" +\n",
    "      f\"MAE: {mean_absolute_error(y_val, y_pred)}\\n\" +\n",
    "      f\"Mean_APE: {mean_absolute_percentage_error(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfcd3c8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID\": test[\"ID\"],\n",
    "              \"target\": np.exp(model.predict(test[cat_features + numeric_features]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d6155",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe006f29",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b219212",
   "metadata": {},
   "source": [
    "# OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277fb2d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "# Предобработка данных\n",
    "test[cat_features] = test[cat_features].fillna(\"NaN\")\n",
    "train[cat_features] = train[cat_features].fillna(\"NaN\")\n",
    "train['target'] = np.log(train['price_TARGET'])\n",
    "\n",
    "# Метрика MedianAPE\n",
    "class MedianAPE:\n",
    "    @staticmethod\n",
    "    def get_median_ape(y_true, y_pred, eps=1e-8):\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n",
    "    \n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "    \n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        y_true = np.array(target)\n",
    "        y_pred = np.array(approxes[0])\n",
    "        score = self.get_median_ape(y_true, y_pred)\n",
    "        return score, 1\n",
    "    \n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "def median_APE(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n",
    "\n",
    "# Разделение данных\n",
    "X = train[cat_features + numeric_features]\n",
    "y = train['target']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=52, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ba385",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Функция для оптимизации\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 1000, 7500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 11),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 2),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 250),\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': MedianAPE(),\n",
    "        'cat_features': cat_features,\n",
    "        'verbose': False,\n",
    "        'random_seed': 42,\n",
    "        'task_type': 'GPU',\n",
    "        # \"early_stopping_rounds\": 250\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(**params)\n",
    "    \n",
    "    try:\n",
    "        model.fit(\n",
    "            X=X_train, y=y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Предсказание и оценка\n",
    "        y_pred = np.exp(model.predict(X_val))\n",
    "        y_true = train.loc[X_val.index, \"price_TARGET\"]\n",
    "        score = median_APE(y_true, y_pred)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обучении: {e}\")\n",
    "        score = float('inf')\n",
    "        \n",
    "    return score\n",
    "\n",
    "# Исследование\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=RandomSampler(seed=16)\n",
    ")\n",
    "study.optimize(objective, n_trials=600)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Лучшие параметры:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"Лучший Median_APE: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ed1ad",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf21a02",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pars = {'iterations': 4773,\n",
    " 'learning_rate': 0.023540714865270384,\n",
    " 'depth': 11,\n",
    " 'l2_leaf_reg': 4.339528598041656,\n",
    " 'random_strength': 1.4767698885793084,\n",
    " 'bagging_temperature': 0.5228168517505888,\n",
    " 'border_count': 186,\n",
    " 'grow_policy': 'Depthwise',\n",
    " 'min_data_in_leaf': 76}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5005554",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pars_redacted = {'iterations': 1242,\n",
    " 'learning_rate': 0.023540714865270384,\n",
    " 'depth': 11,\n",
    " 'l2_leaf_reg': 4.339528598041656,\n",
    " 'random_strength': 1.4767698885793084,\n",
    " 'bagging_temperature': 0.5228168517505888,\n",
    " 'border_count': 186,\n",
    " 'grow_policy': 'Depthwise',\n",
    " 'min_data_in_leaf': 76}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92fe95",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Финальное обучение с лучшими параметрами\n",
    "best_model = CatBoostRegressor(\n",
    "    **pars,\n",
    "    cat_features=cat_features,\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=MedianAPE(),\n",
    "    verbose=100,\n",
    "    random_seed=42,\n",
    "    task_type=\"GPU\"\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X=X_train, y=y_train,\n",
    "    eval_set=(X_val, y_val),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26718c2e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Финальная оценка\n",
    "y_pred = np.exp(best_model.predict(X_val))\n",
    "y_true = train.loc[X_val.index, \"price_TARGET\"]\n",
    "final_score = median_APE(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nФинальный Median_APE: {final_score}\")\n",
    "print(f\"LB score: {1 / (1 + final_score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299bb60",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID\": test[\"ID\"],\n",
    "              \"target\": np.exp(best_model.predict(test[cat_features + numeric_features]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee8691",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"opt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5e800",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8370364,
     "sourceId": 13206775,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
